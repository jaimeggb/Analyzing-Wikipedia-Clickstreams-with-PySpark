{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "d8b84805",
   "metadata": {},
   "source": [
    "# Analyzing Wikipedia Clickstream Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fddc058",
   "metadata": {},
   "source": [
    "### Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "33467f42",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "b2313603",
   "metadata": {},
   "source": [
    "## Introduction to Clickstream Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "13837f16",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a new SparkSession\n",
    "spark = SparkSession.builder \\\n",
    "    .master(\"local[1]\") \\\n",
    "    .appName(\"SparkByExamples.com\") \\\n",
    "    .getOrCreate() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "92b1a38b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sample clickstream counts\n",
    "sample_clickstream_counts = [\n",
    "    [\"other-search\", \"Hanging_Gardens_of_Babylon\", \"external\", 47000],\n",
    "    [\"other-empty\", \"Hanging_Gardens_of_Babylon\", \"external\", 34600],\n",
    "    [\"Wonders_of_the_World\", \"Hanging_Gardens_of_Babylon\", \"link\", 14000],\n",
    "    [\"Babylon\", \"Hanging_Gardens_of_Babylon\", \"link\", 2500]\n",
    "]\n",
    "\n",
    "# Create RDD from sample data\n",
    "clickstream_counts_rdd = spark.sparkContext.parallelize( sample_clickstream_counts )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "12dd3ee7",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+--------------------+-------------+----------+\n",
      "|         source_page|         target_page|link_category|link_count|\n",
      "+--------------------+--------------------+-------------+----------+\n",
      "|        other-search|Hanging_Gardens_o...|     external|     47000|\n",
      "|         other-empty|Hanging_Gardens_o...|     external|     34600|\n",
      "|Wonders_of_the_World|Hanging_Gardens_o...|         link|     14000|\n",
      "|             Babylon|Hanging_Gardens_o...|         link|      2500|\n",
      "+--------------------+--------------------+-------------+----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Create a DataFrame from the RDD of sample clickstream counts\n",
    "clickstream_sample_df = clickstream_counts_rdd.toDF([\"source_page\", \"target_page\", \"link_category\", \"link_count\"])\n",
    "\n",
    "# Display the DataFrame to the notebook\n",
    "clickstream_sample_df.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "1268c0b0",
   "metadata": {},
   "source": [
    "## Inspecting Clickstream Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b1e284f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------+--------------------+-------------+-------------+-----------+\n",
      "|           referrer|            resource|link_category|language_code|click_count|\n",
      "+-------------------+--------------------+-------------+-------------+-----------+\n",
      "|   Daniel_Day-Lewis|      Phantom_Thread|         link|           en|      43190|\n",
      "|     other-internal|      Phantom_Thread|     external|           en|      21683|\n",
      "|        other-empty|      Phantom_Thread|     external|           en|     169532|\n",
      "|90th_Academy_Awards|      Phantom_Thread|         link|           en|      40449|\n",
      "|       other-search|      Phantom_Thread|     external|           en|     536940|\n",
      "|       other-search|Tara_Grinstead_mu...|     external|           en|      30041|\n",
      "|       other-search|      Yossi_Benayoun|     external|           en|      11045|\n",
      "|        other-empty|       Parthiv_Patel|     external|           en|      11481|\n",
      "|       other-search|       Parthiv_Patel|     external|           en|      34953|\n",
      "|        other-empty|   Cosimo_de'_Medici|     external|           en|      16418|\n",
      "|       other-search|   Cosimo_de'_Medici|     external|           en|      22190|\n",
      "|       other-search|University_of_Geo...|     external|           en|      29963|\n",
      "|        other-empty|University_of_Geo...|     external|           en|      17325|\n",
      "|       other-search|Carbon_monoxide_d...|     external|           en|      13617|\n",
      "|        other-empty|      Marissa_Ribisi|     external|           en|      18979|\n",
      "|             Shinee|Kim_Jong-hyun_(si...|         link|           en|      24433|\n",
      "|       other-search|Kim_Jong-hyun_(si...|     external|           en|     162466|\n",
      "|        other-empty|Kim_Jong-hyun_(si...|     external|           en|      60193|\n",
      "|        other-empty|         Hello_Kitty|     external|           en|      10674|\n",
      "|       other-search|         Hello_Kitty|     external|           en|      23726|\n",
      "+-------------------+--------------------+-------------+-------------+-----------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Read the target directory (`./cleaned/clickstream/`) into a DataFrame (`clickstream`)\n",
    "clickstream = spark.read.options(header='True', delimiter='\\t', inferSchema = 'True').csv(\"./cleaned/clickstream/\")\n",
    "\n",
    "# Display the DataFrame to the notebook\n",
    "clickstream.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "934cc169",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- referrer: string (nullable = true)\n",
      " |-- resource: string (nullable = true)\n",
      " |-- link_category: string (nullable = true)\n",
      " |-- language_code: string (nullable = true)\n",
      " |-- click_count: integer (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Display the schema of the `clickstream` DataFrame to the notebook\n",
    "clickstream.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "17fa2a20",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------+--------------+-------------+-----------+\n",
      "|           referrer|      resource|link_category|click_count|\n",
      "+-------------------+--------------+-------------+-----------+\n",
      "|   Daniel_Day-Lewis|Phantom_Thread|         link|      43190|\n",
      "|     other-internal|Phantom_Thread|     external|      21683|\n",
      "|        other-empty|Phantom_Thread|     external|     169532|\n",
      "|90th_Academy_Awards|Phantom_Thread|         link|      40449|\n",
      "|       other-search|Phantom_Thread|     external|     536940|\n",
      "+-------------------+--------------+-------------+-----------+\n",
      "only showing top 5 rows\n",
      "\n",
      "root\n",
      " |-- referrer: string (nullable = true)\n",
      " |-- resource: string (nullable = true)\n",
      " |-- link_category: string (nullable = true)\n",
      " |-- click_count: integer (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Drop target columns\n",
    "clickstream = clickstream.drop(\"language_code\")\n",
    "\n",
    "# Display the first few rows of the DataFrame\n",
    "clickstream.show(5)\n",
    "\n",
    "# Display the new schema in the notebook\n",
    "clickstream.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0b75baed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------+--------------+-------------+-----------+\n",
      "|        source_page|   target_page|link_category|click_count|\n",
      "+-------------------+--------------+-------------+-----------+\n",
      "|   Daniel_Day-Lewis|Phantom_Thread|         link|      43190|\n",
      "|     other-internal|Phantom_Thread|     external|      21683|\n",
      "|        other-empty|Phantom_Thread|     external|     169532|\n",
      "|90th_Academy_Awards|Phantom_Thread|         link|      40449|\n",
      "|       other-search|Phantom_Thread|     external|     536940|\n",
      "+-------------------+--------------+-------------+-----------+\n",
      "only showing top 5 rows\n",
      "\n",
      "root\n",
      " |-- source_page: string (nullable = true)\n",
      " |-- target_page: string (nullable = true)\n",
      " |-- link_category: string (nullable = true)\n",
      " |-- click_count: integer (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Rename `referrer` and `resource` to `source_page` and `target_page` \n",
    "clickstream = clickstream.withColumnRenamed(\"referrer\",\"source_page\")\n",
    "clickstream = clickstream.withColumnRenamed(\"resource\",\"target_page\")\n",
    "  \n",
    "# Display the first few rows of the DataFrame\n",
    "clickstream.show(5)\n",
    "\n",
    "# Display the new schema in the notebook\n",
    "clickstream.printSchema()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "572ce589",
   "metadata": {},
   "source": [
    "## Querying Clickstream Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f017bdd8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['source_page', 'target_page', 'link_category', 'click_count']\n"
     ]
    }
   ],
   "source": [
    "# Create a temporary view in the metadata for this `SparkSession` \n",
    "clickstream.createOrReplaceTempView('clickstream')\n",
    "print(clickstream.columns)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6c20a4de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+--------------------+-------------+-----------+\n",
      "|         source_page|         target_page|link_category|click_count|\n",
      "+--------------------+--------------------+-------------+-----------+\n",
      "|Seven_Wonders_of_...|Hanging_Gardens_o...|         link|      12296|\n",
      "|Wonders_of_the_World|Hanging_Gardens_o...|         link|      14668|\n",
      "|         other-empty|Hanging_Gardens_o...|     external|      34619|\n",
      "|        other-search|Hanging_Gardens_o...|     external|      47088|\n",
      "+--------------------+--------------------+-------------+-----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Filter and sort the DataFrame using PySpark DataFrame methods\n",
    "clickstream.filter(clickstream[\"target_page\"] == \"Hanging_Gardens_of_Babylon\").sort(\"click_count\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a49bbec6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+--------------------+-------------+-----------+\n",
      "|         source_page|         target_page|link_category|click_count|\n",
      "+--------------------+--------------------+-------------+-----------+\n",
      "|Seven_Wonders_of_...|Hanging_Gardens_o...|         link|      12296|\n",
      "|Wonders_of_the_World|Hanging_Gardens_o...|         link|      14668|\n",
      "|         other-empty|Hanging_Gardens_o...|     external|      34619|\n",
      "|        other-search|Hanging_Gardens_o...|     external|      47088|\n",
      "+--------------------+--------------------+-------------+-----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Filter and sort the DataFrame using SQL\n",
    "query = \"\"\" SELECT * FROM clickstream WHERE target_page = 'Hanging_Gardens_of_Babylon' ORDER BY click_count \"\"\"\n",
    "spark.sql(query).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "38bac86c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------+----------------+\n",
      "|link_category|sum(click_count)|\n",
      "+-------------+----------------+\n",
      "|         link|        97805811|\n",
      "|        other|         9338172|\n",
      "|     external|      3248677856|\n",
      "+-------------+----------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Aggregate the DataFrame using PySpark DataFrame Methods \n",
    "clickstream.groupBy(clickstream.link_category).sum().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "817ff99e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------+-----------+\n",
      "|link_category|total_count|\n",
      "+-------------+-----------+\n",
      "|         link|   97805811|\n",
      "|        other|    9338172|\n",
      "|     external| 3248677856|\n",
      "+-------------+-----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Aggregate the DataFrame using SQL\n",
    "query = \"\"\"\n",
    "SELECT link_category, SUM(click_count) as total_count\n",
    "FROM clickstream\n",
    "GROUP BY link_category;\n",
    "\"\"\"\n",
    "spark.sql(query).show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "c8b756c1",
   "metadata": {},
   "source": [
    "## Saving Results to Disk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "29e74d43",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------+--------------------+--------------------+\n",
      "|link_category|         source_page|         target_page|\n",
      "+-------------+--------------------+--------------------+\n",
      "|         link|    Daniel_Day-Lewis|      Phantom_Thread|\n",
      "|         link| 90th_Academy_Awards|      Phantom_Thread|\n",
      "|         link|              Shinee|Kim_Jong-hyun_(si...|\n",
      "|         link|      Agnyaathavaasi|        Anu_Emmanuel|\n",
      "|         link|      Naa_Peru_Surya|        Anu_Emmanuel|\n",
      "|         link|        Mariah_Carey|         Nick_Cannon|\n",
      "|         link|               Kesha|Rainbow_(Kesha_al...|\n",
      "|         link|  David_Attenborough|   John_Attenborough|\n",
      "|         link|            Boney_M.|       Bobby_Farrell|\n",
      "|         link|The_End_of_the_F*...|      Jessica_Barden|\n",
      "|         link|   Quentin_Tarantino|   The_Hateful_Eight|\n",
      "|         link|Ready_Player_One_...|        Olivia_Cooke|\n",
      "|         link| Royal_Rumble_(2018)|Kevin_Owens_and_S...|\n",
      "|         link|     Macaulay_Culkin|         Brenda_Song|\n",
      "|         link|      Altered_Carbon|Altered_Carbon_(T...|\n",
      "|         link|            Lil_Pump|          Smokepurpp|\n",
      "|         link|       Fifth_Harmony|      Camila_Cabello|\n",
      "|         link|Havana_(Camila_Ca...|      Camila_Cabello|\n",
      "|         link|    Jennifer_Aniston|        John_Aniston|\n",
      "|         link|Kingsman:_The_Gol...|Kingsman:_The_Sec...|\n",
      "+-------------+--------------------+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Create a new DataFrame named `internal_clickstream`\n",
    "internal_clickstream = clickstream.select(\"link_category\", \"source_page\", \"target_page\").filter(clickstream.link_category == 'link')\n",
    "\n",
    "# Display the first few rows of the DataFrame in the notebook\n",
    "internal_clickstream.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "93c015ca",
   "metadata": {},
   "outputs": [
    {
     "ename": "AnalysisException",
     "evalue": "path file:/home/ccuser/workspace/pyspark-sql-project/results/article_to_article_csv already exists.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAnalysisException\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[20], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Save the `internal_clickstream` DataFrame to a series of CSV files\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m \u001b[43minternal_clickstream\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwrite\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcsv\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m./results/article_to_article_csv/\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/pyspark/sql/readwriter.py:955\u001b[0m, in \u001b[0;36mDataFrameWriter.csv\u001b[0;34m(self, path, mode, compression, sep, quote, escape, header, nullValue, escapeQuotes, quoteAll, dateFormat, timestampFormat, ignoreLeadingWhiteSpace, ignoreTrailingWhiteSpace, charToEscapeQuoteEscaping, encoding, emptyValue, lineSep)\u001b[0m\n\u001b[1;32m    947\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmode(mode)\n\u001b[1;32m    948\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_set_opts(compression\u001b[38;5;241m=\u001b[39mcompression, sep\u001b[38;5;241m=\u001b[39msep, quote\u001b[38;5;241m=\u001b[39mquote, escape\u001b[38;5;241m=\u001b[39mescape, header\u001b[38;5;241m=\u001b[39mheader,\n\u001b[1;32m    949\u001b[0m                nullValue\u001b[38;5;241m=\u001b[39mnullValue, escapeQuotes\u001b[38;5;241m=\u001b[39mescapeQuotes, quoteAll\u001b[38;5;241m=\u001b[39mquoteAll,\n\u001b[1;32m    950\u001b[0m                dateFormat\u001b[38;5;241m=\u001b[39mdateFormat, timestampFormat\u001b[38;5;241m=\u001b[39mtimestampFormat,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    953\u001b[0m                charToEscapeQuoteEscaping\u001b[38;5;241m=\u001b[39mcharToEscapeQuoteEscaping,\n\u001b[1;32m    954\u001b[0m                encoding\u001b[38;5;241m=\u001b[39mencoding, emptyValue\u001b[38;5;241m=\u001b[39memptyValue, lineSep\u001b[38;5;241m=\u001b[39mlineSep)\n\u001b[0;32m--> 955\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_jwrite\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcsv\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpath\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/py4j/java_gateway.py:1321\u001b[0m, in \u001b[0;36mJavaMember.__call__\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m   1315\u001b[0m command \u001b[38;5;241m=\u001b[39m proto\u001b[38;5;241m.\u001b[39mCALL_COMMAND_NAME \u001b[38;5;241m+\u001b[39m\\\n\u001b[1;32m   1316\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcommand_header \u001b[38;5;241m+\u001b[39m\\\n\u001b[1;32m   1317\u001b[0m     args_command \u001b[38;5;241m+\u001b[39m\\\n\u001b[1;32m   1318\u001b[0m     proto\u001b[38;5;241m.\u001b[39mEND_COMMAND_PART\n\u001b[1;32m   1320\u001b[0m answer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgateway_client\u001b[38;5;241m.\u001b[39msend_command(command)\n\u001b[0;32m-> 1321\u001b[0m return_value \u001b[38;5;241m=\u001b[39m \u001b[43mget_return_value\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1322\u001b[0m \u001b[43m    \u001b[49m\u001b[43manswer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgateway_client\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtarget_id\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1324\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m temp_arg \u001b[38;5;129;01min\u001b[39;00m temp_args:\n\u001b[1;32m   1325\u001b[0m     temp_arg\u001b[38;5;241m.\u001b[39m_detach()\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/pyspark/sql/utils.py:117\u001b[0m, in \u001b[0;36mcapture_sql_exception.<locals>.deco\u001b[0;34m(*a, **kw)\u001b[0m\n\u001b[1;32m    113\u001b[0m converted \u001b[38;5;241m=\u001b[39m convert_exception(e\u001b[38;5;241m.\u001b[39mjava_exception)\n\u001b[1;32m    114\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(converted, UnknownException):\n\u001b[1;32m    115\u001b[0m     \u001b[38;5;66;03m# Hide where the exception came from that shows a non-Pythonic\u001b[39;00m\n\u001b[1;32m    116\u001b[0m     \u001b[38;5;66;03m# JVM exception message.\u001b[39;00m\n\u001b[0;32m--> 117\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m converted \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28mNone\u001b[39m\n\u001b[1;32m    118\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    119\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m\n",
      "\u001b[0;31mAnalysisException\u001b[0m: path file:/home/ccuser/workspace/pyspark-sql-project/results/article_to_article_csv already exists."
     ]
    }
   ],
   "source": [
    "# Save the `internal_clickstream` DataFrame to a series of CSV files\n",
    "internal_clickstream.write.csv(\"./results/article_to_article_csv/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "3d542098",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the `internal_clickstream` DataFrame to a series of parquet files\n",
    "internal_clickstream.write.parquet(\"./results/article_to_article_pq/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "55b2c378",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Stop the notebook's `SparkSession` and `SparkContext`\n",
    "spark.stop()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
